{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goal of this project is to identify and mark the driving lanes in the provided input images.  \n",
    "\n",
    "The steps of this project are the following:\n",
    "\n",
    "* Setups\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S1.  Compute the camera calibration matrix and distortion coefficients given a set of chessboard images  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S2.  Obtain warp matrix for perspective transform  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S3.  Setup helper functions for color transform / thresholding  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S4.  Setup helper functions for lane recognition  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; S5.  Setup helper functions for curvature calculation  \n",
    "\n",
    "* Applications  \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A1. Apply a distortion correction to raw images  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A2. Use color transforms, gradients, etc., to create a thresholded binary image  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A3. Apply a perspective transform to rectify binary image (\"birds-eye view\")  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A4. Detect lane pixels and fit to find the lane boundary  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A5. Determine the curvature of the lane and vehicle position with respect to center  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A6. Warp the detected lane boundaries back onto the original image  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A7. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1. Get camera calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library list\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1.1 (optional). Visualize and save the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x130181588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = cv2.imread('camera_cal/calibration4.jpg')\n",
    "img = cv2.undistort(orig, mtx, dist, None, mtx)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(orig)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(img)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12b8df5f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('test_images/test3.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Apply camera calibration\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('camera_cal/test_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## S2. Obtain warp matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1305f29b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Warp perspective to get bird-eye view\n",
    "#  Use an image of undistorted straight lane to get source points\n",
    "img = cv2.imread('test_images/test5.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "print(img_size)\n",
    "plt.clf()\n",
    "plt.imshow(undistorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12fe3e828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 points on warpSrc are manually picked based on observation\n",
    "warpSrc = np.float32([[430.5, 566], [867.7, 566],[1052, 682],[269, 682]])\n",
    "warpDst = np.float32([[269, 566], [1052, 566], [1052, 682], [269, 682]])\n",
    "\n",
    "# Warp matrix and its inverse\n",
    "M = cv2.getPerspectiveTransform(warpSrc, warpDst)\n",
    "Minv = cv2.getPerspectiveTransform(warpDst, warpSrc)\n",
    "\n",
    "# If need to visualize\n",
    "warped = cv2.warpPerspective(undistorted, M, img_size, flags=cv2.INTER_NEAREST) \n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3. Helper functions for color and gradient threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: format of the original image is BGR, NOT RGB, since the images are imported by OpenCV\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # 1. Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 2. Take the derivative in each direction and take absolute value\n",
    "    if orient == 'x':\n",
    "        absSobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        absSobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    # 3. Scale to 8-bit and convert to uint8\n",
    "    scaledSobel = np.uint8(255*absSobel/np.max(absSobel))\n",
    "    # 4. Create a mask of 1s based on threshold\n",
    "    grad_binary = np.zeros_like(scaledSobel)\n",
    "    grad_binary[(scaledSobel >= thresh[0]) & (scaledSobel <= thresh[1])] = 1\n",
    "    # Return result\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    # 1. Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 2. Take the derivative in both directions and take absolute values\n",
    "    absX = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    absY = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    # 3. Take the magnitude of derivatives\n",
    "    absXY = np.sqrt(absX**2 + absY**2)\n",
    "    # 4. Scale to 8-bit and convert to uint8\n",
    "    scaledXY = np.uint8(255*absXY/np.max(absXY))\n",
    "    # 5. Create a mask of 1s based on threshold\n",
    "    mag_binary = np.zeros_like(scaledXY)\n",
    "    mag_binary[(scaledXY >= mag_thresh[0])&(scaledXY <= mag_thresh[1])] = 1 \n",
    "    # Return result\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # 1. Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 2. Take the derivative in both directions and take absolute values\n",
    "    absX = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    absY = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    # 3. Take the direction of derivatives\n",
    "    absDir = np.arctan2(absY, absX)\n",
    "    # 4. Create a mask of 1s based on threshold\n",
    "    dir_binary = np.zeros_like(absDir)\n",
    "    dir_binary[(absDir >= thresh[0]) & (absDir <= thresh[1])] = 1\n",
    "    # Return result\n",
    "    return dir_binary\n",
    "\n",
    "def B_thresh(img, thresh=(0,255)):\n",
    "    unicolor = img[:,:,0]\n",
    "    output = np.zeros_like(unicolor)\n",
    "    output[(unicolor >= thresh[0]) & (unicolor <= thresh[1])] = 1\n",
    "    return output\n",
    "\n",
    "def G_thresh(img, thresh=(0,255)):\n",
    "    unicolor = img[:,:,1]\n",
    "    output = np.zeros_like(unicolor)\n",
    "    output[(unicolor >= thresh[0]) & (unicolor <= thresh[1])] = 1\n",
    "    return output\n",
    "\n",
    "def R_thresh(img, thresh=(0,255)):\n",
    "    unicolor = img[:,:,2]\n",
    "    output = np.zeros_like(unicolor)\n",
    "    output[(unicolor >= thresh[0]) & (unicolor <= thresh[1])] = 1\n",
    "    return output\n",
    "\n",
    "def H_thresh(img, thresh=(0,255), dynamicMode = 0):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    unicolor = img[:,:,0]\n",
    "    \n",
    "    if dynamicMode == 1:\n",
    "        temp = np.amax(unicolor)\n",
    "        thresh = (temp*thresh[0], temp)\n",
    "    \n",
    "    output = np.zeros_like(unicolor)\n",
    "    output[(unicolor >= thresh[0]) & (unicolor <= thresh[1])] = 1\n",
    "    return output\n",
    "\n",
    "def L_thresh(img, thresh=(0,255)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    unicolor = img[:,:,1]\n",
    "    output = np.zeros_like(unicolor)\n",
    "    output[(unicolor >= thresh[0]) & (unicolor <= thresh[1])] = 1\n",
    "    return output\n",
    "\n",
    "def S_thresh(img, thresh=(0,255), dynamicMode = 0):\n",
    "    # When dinamicMode = 1, thresh = (relativeStrength, None)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    unicolor = img[:,:,2]\n",
    "    \n",
    "    if dynamicMode == 1:\n",
    "        temp = np.amax(unicolor)\n",
    "        thresh = (temp*thresh[0], temp)\n",
    "    \n",
    "    output = np.zeros_like(unicolor)\n",
    "    output[(unicolor >= thresh[0]) & (unicolor <= thresh[1])] = 1\n",
    "    return output\n",
    "\n",
    "def regionOfInterest(img, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def colorTransform(undistorted):\n",
    "    gradx = abs_sobel_thresh(undistorted, orient='x', sobel_kernel=15, thresh=(30, 100))\n",
    "    HLSS = S_thresh(undistorted, thresh=(0.5, 0), dynamicMode = 1) # originally: (150,255)\n",
    "    HLSH = H_thresh(undistorted, thresh=(70, 100), dynamicMode = 0)\n",
    "    BGRR = R_thresh(undistorted, thresh=(200,255))\n",
    "    magBinary = mag_thresh(undistorted, sobel_kernel=9, mag_thresh=(50, 150))\n",
    "    dirBinary = dir_threshold(undistorted, sobel_kernel=15, thresh=(0.8, 1.1))\n",
    "\n",
    "    combined = np.zeros_like(gradx)\n",
    "    combined[(HLSH == 1) & (HLSS == 1) | ((BGRR == 1))] = 1\n",
    "    #((gradx == 1) & (magBinary == 1))\n",
    "    #combined[(HLSS == 1)] = 1\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13ff77400>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing space for parameter tuning\n",
    "#leftVertics = np.array([[(200,470),(500, 470),(700,500),(600,600),(330, 650),(330,720),(230,720),(230,650),(120,600),(120,500)]],dtype=np.int32)\n",
    "leftVertics = np.array([[(150,720),(400,430),(700,430),(700,720)]])\n",
    "#rightVertics = np.array([[(900,470),(1080, 470),(1280,500),(1280,600),(1170,650),(1170,720),(1070,720),(1070,650),(800,600),(700,500)]],dtype=np.int32)\n",
    "rightVertics = np.array([[(1250,720),(1000,430),(700,430),(700,720)]],dtype=np.int32)\n",
    "\n",
    "leftCropped = regionOfInterest(undistorted,leftVertics)\n",
    "rightCropped = regionOfInterest(undistorted,rightVertics)\n",
    "    \n",
    "# A2. Use color transforms, gradients, etc., to create a thresholded binary image\n",
    "leftCombined = colorTransform(leftCropped)\n",
    "rightCombined = colorTransform(undistorted)\n",
    "#plt.imshow(undistorted)\n",
    "#plt.clf()\n",
    "#plt.imshow(rightCombined)\n",
    "#warped = cv2.warpPerspective(rightCombined, M, img_size, flags=cv2.INTER_NEAREST)\n",
    "#plt.clf()\n",
    "#plt.imshow(warped)\n",
    "HLSH = H_thresh(undistorted, thresh=(70,100), dynamicMode = 0)\n",
    "HLSS = S_thresh(undistorted, thresh=(0.5,0), dynamicMode = 1)\n",
    "RGBR = R_thresh(undistorted, thresh=(200,255))\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10))\n",
    "ax1.imshow(undistorted)\n",
    "ax1.set_title('Original Image', fontsize=10)\n",
    "ax2.imshow(HLSH)\n",
    "ax2.set_title('H-Channel: thresh = (70-100)', fontsize=10)\n",
    "ax3.imshow(HLSS)\n",
    "ax3.set_title('S-Channel: thresh = (128-255)', fontsize=10)\n",
    "ax4.imshow(RGBR)\n",
    "ax4.set_title('R-Channel: thresh = (200-255)', fontsize=10)\n",
    "plt.clf()\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "ax1.imshow(leftCropped)\n",
    "ax1.set_title('Region of Interest: Left', fontsize=10)\n",
    "ax2.imshow(rightCropped)\n",
    "ax2.set_title('Region of Interest: Right', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S4.  Setup helper functions for lane recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindowsHelper(binary_warped, _base, nwindows, bias, lr):\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    _current = _base\n",
    "\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    _lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low =  (window)*window_height\n",
    "        win_y_high = (window+1)*window_height\n",
    "        win_x_low = _current - margin\n",
    "        win_x_high = _current + margin\n",
    "\n",
    "        # Draw the windows on the visualization image\n",
    "        #cv2.rectangle(out_img,(win_x_low,win_y_low),(win_x_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_x_low) & (nonzerox < win_x_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        _lane_inds.append(good_inds)\n",
    "        \n",
    "        if bias == 1:\n",
    "            base_y_low = 0\n",
    "            base_y_high = 80\n",
    "            if lr == 'L':\n",
    "                base_x_low = 230\n",
    "                base_x_high = 330\n",
    "            elif lr == 'R':\n",
    "                base_x_low = 1070\n",
    "                base_x_high = 1170\n",
    "            good_inds = ((nonzeroy >= base_y_low) & (nonzeroy < base_y_high) & (nonzerox >= base_x_low) & (nonzerox < base_x_high)).nonzero()[0]\n",
    "        \n",
    "            # Append these indices to the lists\n",
    "            _lane_inds.append(good_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_inds) > minpix:\n",
    "            _current = np.int(np.mean(nonzerox[good_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    _lane_inds = np.concatenate(_lane_inds)\n",
    "    \n",
    "    return _lane_inds, nonzerox, nonzeroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindows(left_binary_warped, right_binary_warped, leftLine, rightLine, nwindows = 9, confidenceCheck = 1, polynomialCheck =1, segmentCheck = 1, debugMode = 0):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    leftHistogram = np.sum(left_binary_warped[:left_binary_warped.shape[0]//2,:], axis=0)\n",
    "    rightHistogram = np.sum(right_binary_warped[:right_binary_warped.shape[0]//2,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    #out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    #midpoint = np.int(histogram.shape[0]/2)\n",
    "    #leftx_base = np.argmax(histogram[:midpoint])\n",
    "    #rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    leftx_base = np.argmax(leftHistogram)\n",
    "    rightx_base = np.argmax(rightHistogram)\n",
    "    \n",
    "    left_lane_inds, leftNonzerox, leftNonzeroy = slidingWindowsHelper(left_binary_warped, leftx_base, nwindows, bias = 0, lr = 'L')\n",
    "    right_lane_inds, rightNonzerox, rightNonzeroy = slidingWindowsHelper(right_binary_warped, rightx_base, nwindows, bias = 0, lr = 'R')\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftLine.addAllX(leftNonzerox[left_lane_inds])\n",
    "    leftLine.addAllY(leftNonzeroy[left_lane_inds])\n",
    "    rightLine.addAllX(rightNonzerox[right_lane_inds])\n",
    "    rightLine.addAllY(rightNonzeroy[right_lane_inds])\n",
    "    \n",
    "    # Initialize variables\n",
    "    leftLine.current_fit = []\n",
    "    rightLine.current_fit = []\n",
    "    leftLine.best_fit = None\n",
    "    rightLine.best_fit = None\n",
    "    leftLine.diffs = [0,0,0]\n",
    "    rightLine.diffs = [0,0,0]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    leftLine.runningWindow(np.polyfit(leftLine.ally, leftLine.allx, 2))\n",
    "    rightLine.runningWindow(np.polyfit(rightLine.ally, rightLine.allx, 2))\n",
    "    \n",
    "    # Check how confident each polynomial fit is\n",
    "    if confidenceCheck == 1:\n",
    "        leftLine.noLineFound = False\n",
    "        rightLine.noLineFound = False\n",
    "        if len(left_lane_inds) < 500:\n",
    "            leftLine.lowConfidenceFlag += 1\n",
    "        elif leftLine.lowConfidenceFlag >= 0:\n",
    "            leftLine.lowConfidenceFlag -= 1\n",
    "        if len(right_lane_inds) < 500:\n",
    "            rightLine.lowConfidenceFlag += 1\n",
    "        elif rightLine.lowConfidenceFlag >= 0:\n",
    "            rightLine.lowConfidenceFlag -= 1\n",
    "        \n",
    "        if (leftLine.lowConfidenceFlag > 2 and rightLine.lowConfidenceFlag <= 2):\n",
    "            if len(leftLine.current_fit)>1:\n",
    "                leftLine.current_fit = np.delete(leftLine.current_fit, -1, 0)\n",
    "                new = [rightLine.best_fit[0]-0.3*np.absolute(rightLine.best_fit[0]), rightLine.best_fit[1], leftLine.best_fit[2]]\n",
    "                if len(leftLine.current_fit)>1:\n",
    "                    leftLine.current_fit = np.vstack((leftLine.current_fit, new))\n",
    "                else:\n",
    "                    leftLine.current_fit = [new]\n",
    "            leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "            leftLine.lowConfidenceFlag -= 1\n",
    "        elif (leftLine.lowConfidenceFlag <= 2 and rightLine.lowConfidenceFlag > 2):\n",
    "            if len(rightLine.current_fit)>1:\n",
    "                rightLine.current_fit = np.delete(rightLine.current_fit, -1, 0)\n",
    "                new = [leftLine.best_fit[0]+0.3*np.absolute(leftLine.best_fit[0]), leftLine.current_fit[1], rightLine.best_fit[2]]\n",
    "                if len(rightLine.current_fit)>1:\n",
    "                    rightLine.current_fit = np.vstack((rightLine.current_fit, new))\n",
    "                else:\n",
    "                    rightLine.current_fit = [new]\n",
    "            rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "            rightLine.lowConfidenceFlag -= 1\n",
    "        elif (leftLine.lowConfidenceFlag > 2 and rightLine.lowConfidenceFlag > 2):\n",
    "            leftLine.noLineFound = True\n",
    "            leftLine.lowConfidenceFlag -= 1\n",
    "            rightLine.noLineFound = True\n",
    "            rightLine.lowConfidenceFlag -= 1\n",
    "        \n",
    "        leftLine.confidence = len(left_lane_inds)\n",
    "        rightLine.confidence = len(right_lane_inds)\n",
    "\n",
    "    \n",
    "    # Check if the segment of fitted line sits in resonable range\n",
    "    if segmentCheck == 1:\n",
    "        LL = 170\n",
    "        LR = 450\n",
    "        RL = 950\n",
    "        RR = 1130\n",
    "        \n",
    "        if (leftLine.best_fit[2] > LL and leftLine.best_fit[2] < LR) != 1:\n",
    "            if (rightLine.best_fit[2] > RL and rightLine.best_fit[2] < RR) != 1: # Left & Right segment out of range\n",
    "                if len(leftLine.current_fit) > 1:\n",
    "                    leftLine.current_fit = np.delete(leftLine.current_fit, -1, 0)\n",
    "                leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "                if len(rightLine.current_fit) > 1:\n",
    "                    rightLine.current_fit = np.delete(rightLine.current_fit, -1, 0)\n",
    "                rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "                print('check1 used')\n",
    "            else: # Only left segment out of range\n",
    "                if len(leftLine.current_fit) > 1:\n",
    "                    leftLine.current_fit = np.delete(leftLine.current_fit, -1, 0)\n",
    "                    new = [rightLine.best_fit[0], rightLine.best_fit[1], leftLine.segment]\n",
    "                    leftLine.current_fit = np.vstack((leftLine.current_fit, new))\n",
    "                    leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "                elif len(leftLine.current_fit) == 1:\n",
    "                    if leftLine.segment == None:\n",
    "                        new = [rightLine.best_fit[0], rightLine.best_fit[1], leftLine.current_fit[-1][2]]\n",
    "                    else:\n",
    "                        new = [rightLine.best_fit[0], rightLine.best_fit[1], leftLine.segment]\n",
    "                    leftLine.current_fit = [new]\n",
    "                    leftLine.best_fit = new\n",
    "                print('check2 used')\n",
    "        else:\n",
    "            if (rightLine.best_fit[2] > RL and rightLine.best_fit[2] < RR) != 1: # Only right segment out of range\n",
    "                if len(rightLine.current_fit) > 1:\n",
    "                    rightLine.current_fit = np.delete(rightLine.current_fit, -1, 0)\n",
    "                    new = [leftLine.best_fit[0], leftLine.best_fit[1], rightLine.segment]\n",
    "                    rightLine.current_fit = np.vstack((rightLine.current_fit, new))\n",
    "                    rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "                elif len(rightLine.current_fit) == 1:\n",
    "                    if rightLine.segment == None:\n",
    "                        new = [leftLine.best_fit[0], leftLine.best_fit[1], rightLine.current_fit[-1][2]]\n",
    "                    else:\n",
    "                        new = [leftLine.best_fit[0], leftLine.best_fit[1], rightLine.segment]\n",
    "                    rightLine.current_fit = [new]\n",
    "                    rightLine.best_fit = new\n",
    "                print('check3 used')\n",
    "            \n",
    "        # Store segment\n",
    "        leftLine.segment = leftLine.best_fit[2]\n",
    "        rightLine.segment = rightLine.best_fit[2]\n",
    "        \n",
    "    # Check if both lines have similar curvature, as lane lines supposed to be near parallel\n",
    "    if polynomialCheck == 1:\n",
    "        # Check if previous number is available\n",
    "        if (leftLine.polyCF != None and rightLine.polyCF != None):\n",
    "            if (np.absolute(leftLine.best_fit[0] - rightLine.best_fit[0]) / min(np.absolute(leftLine.best_fit[0]), np.absolute(rightLine.best_fit[0])) > 3):\n",
    "                # If left is out of range\n",
    "                if (np.absolute(leftLine.polyCF-leftLine.best_fit[0]) > np.absolute(rightLine.polyCF-rightLine.best_fit[0])):\n",
    "                    leftLine.current_fit[-1][0] = rightLine.best_fit[0]\n",
    "                    leftLine.current_fit[-1][1] = rightLine.best_fit[1]\n",
    "                    if (len(leftLine.current_fit) == 1):\n",
    "                        leftLine.best_fit = leftLine.current_fit[-1]\n",
    "                    else:\n",
    "                        leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "                    print('check4 used')\n",
    "                # If right is out of range\n",
    "                else:\n",
    "                    rightLine.current_fit[-1][0] = leftLine.best_fit[0]\n",
    "                    rightLine.current_fit[-1][1] = leftLine.best_fit[1]\n",
    "                    if (len(rightLine.current_fit) == 1):\n",
    "                        rightLine.best_fit = rightLine.current_fit[-1]\n",
    "                    else:\n",
    "                        rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "                    print('check5 used')\n",
    "        \n",
    "        leftLine.polyCF = leftLine.best_fit[0]\n",
    "        rightLine.polyCF = rightLine.best_fit[0]\n",
    "            \n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    leftLine.ploty = np.linspace(0, left_binary_warped.shape[0]-1, left_binary_warped.shape[0] )\n",
    "    rightLine.ploty = np.linspace(0, right_binary_warped.shape[0]-1, right_binary_warped.shape[0] )\n",
    "    leftLine.current_fitx = leftLine.best_fit[0]*leftLine.ploty**2 + leftLine.best_fit[1]*leftLine.ploty + leftLine.best_fit[2]\n",
    "    rightLine.current_fitx = rightLine.best_fit[0]*rightLine.ploty**2 + rightLine.best_fit[1]*rightLine.ploty + rightLine.best_fit[2]\n",
    "\n",
    "    if debugMode == 1:\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        window_img = np.zeros_like(out_img)\n",
    "    \n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([leftLine.current_fitx-margin, leftLine.ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([leftLine.current_fitx+margin, leftLine.ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([rightLine.current_fitx-margin, rightLine.ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([rightLine.current_fitx+margin, rightLine.ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "    \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.imshow(result)\n",
    "    \n",
    "    leftLine.detected = True\n",
    "    rightLine.detected = True\n",
    "    \n",
    "    #return leftLine, rightLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knownLines(left_binary_warped, right_binary_warped, leftLine, rightLine, confidenceCheck = 1, polynomialCheck = 1, segmentCheck = 1, debugMode = 0):\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    leftNonzero = left_binary_warped.nonzero()\n",
    "    leftNonzeroy = np.array(leftNonzero[0])\n",
    "    leftNonzerox = np.array(leftNonzero[1])\n",
    "    rightNonzero = right_binary_warped.nonzero()\n",
    "    rightNonzeroy = np.array(rightNonzero[0])\n",
    "    rightNonzerox = np.array(rightNonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((leftNonzerox > (leftLine.best_fit[0]*(leftNonzeroy**2) + leftLine.best_fit[1]*leftNonzeroy + leftLine.best_fit[2] - margin)) & (leftNonzerox < (leftLine.best_fit[0]*(leftNonzeroy**2) + leftLine.best_fit[1]*leftNonzeroy + leftLine.best_fit[2] + margin))) \n",
    "    right_lane_inds = ((rightNonzerox > (rightLine.best_fit[0]*(rightNonzeroy**2) + rightLine.best_fit[1]*rightNonzeroy + rightLine.best_fit[2] - margin)) & (rightNonzerox < (rightLine.best_fit[0]*(rightNonzeroy**2) + rightLine.best_fit[1]*rightNonzeroy + rightLine.best_fit[2] + margin)))  \n",
    "\n",
    "    leftLine.confidence = len(left_lane_inds)\n",
    "    rightLine.confidence = len(right_lane_inds)\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftLine.addAllX(leftNonzerox[left_lane_inds])\n",
    "    leftLine.addAllY(leftNonzeroy[left_lane_inds])\n",
    "    rightLine.addAllX(rightNonzerox[right_lane_inds])\n",
    "    rightLine.addAllY(rightNonzeroy[right_lane_inds])\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    leftLine.runningWindow(np.polyfit(leftLine.ally, leftLine.allx, 2))\n",
    "    rightLine.runningWindow(np.polyfit(rightLine.ally, rightLine.allx, 2))\n",
    "    \n",
    "    # Check how confident each polynomial fit is\n",
    "    if confidenceCheck == 1:\n",
    "        leftLine.noLineFound = False\n",
    "        rightLine.noLineFound = False\n",
    "        if len(left_lane_inds) < 500:\n",
    "            leftLine.lowConfidenceFlag += 1\n",
    "        elif leftLine.lowConfidenceFlag >= 0:\n",
    "            leftLine.lowConfidenceFlag -= 1\n",
    "        if len(right_lane_inds) < 500:\n",
    "            rightLine.lowConfidenceFlag += 1\n",
    "        elif rightLine.lowConfidenceFlag >= 0:\n",
    "            rightLine.lowConfidenceFlag -= 1\n",
    "        \n",
    "        if (leftLine.lowConfidenceFlag > 2 and rightLine.lowConfidenceFlag <= 2):\n",
    "            if len(leftLine.current_fit)>1:\n",
    "                leftLine.current_fit = np.delete(leftLine.current_fit, -1, 0)\n",
    "                new = [rightLine.best_fit[0]-0.3*np.absolute(rightLine.best_fit[0]), rightLine.best_fit[1], leftLine.best_fit[2]]\n",
    "                if len(leftLine.current_fit)>1:\n",
    "                    leftLine.current_fit = np.vstack((leftLine.current_fit, new))\n",
    "                else:\n",
    "                    leftLine.current_fit = [new]\n",
    "            leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "            leftLine.lowConfidenceFlag -= 1\n",
    "        elif (leftLine.lowConfidenceFlag <= 2 and rightLine.lowConfidenceFlag > 2):\n",
    "            if len(rightLine.current_fit)>1:\n",
    "                rightLine.current_fit = np.delete(rightLine.current_fit, -1, 0)\n",
    "                new = [leftLine.best_fit[0]+0.3*np.absolute(leftLine.best_fit[0]), leftLine.best_fit[1], rightLine.best_fit[2]]\n",
    "                if len(rightLine.current_fit)>1:\n",
    "                    rightLine.current_fit = np.vstack((rightLine.current_fit, new))\n",
    "                else:\n",
    "                    rightLine.current_fit = [new]\n",
    "            rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "            rightLine.lowConfidenceFlag -= 1\n",
    "        elif (leftLine.lowConfidenceFlag > 2 and rightLine.lowConfidenceFlag > 2):\n",
    "            leftLine.noLineFound = True\n",
    "            leftLine.lowConfidenceFlag -= 1\n",
    "            rightLine.noLineFound = True\n",
    "            rightLine.lowConfidenceFlag -= 1\n",
    "        \n",
    "        leftLine.confidence = len(left_lane_inds)\n",
    "        rightLine.confidence = len(right_lane_inds)\n",
    "            \n",
    "    \n",
    "    # Check if the segment of fitted line sits in resonable range\n",
    "    if segmentCheck == 1:\n",
    "        LL = 170\n",
    "        LR = 450\n",
    "        RL = 950\n",
    "        RR = 1130\n",
    "    \n",
    "        if (leftLine.best_fit[2] > LL and leftLine.best_fit[2] < LR) != 1:\n",
    "            if (rightLine.best_fit[2] > RL and rightLine.best_fit[2] < RR) != 1: # Left & Right segment out of range\n",
    "                if len(leftLine.current_fit) > 1:\n",
    "                    leftLine.current_fit = np.delete(leftLine.current_fit, -1, 0)\n",
    "                leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "                if len(rightLine.current_fit) > 1:\n",
    "                    rightLine.current_fit = np.delete(rightLine.current_fit, -1, 0)\n",
    "                rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "                print('check1 used')\n",
    "            else: # Only left segment out of range\n",
    "                if len(leftLine.current_fit) > 1:\n",
    "                    leftLine.current_fit = np.delete(leftLine.current_fit, -1, 0)\n",
    "                    new = [rightLine.best_fit[0], rightLine.best_fit[1], leftLine.segment]\n",
    "                    leftLine.current_fit = np.vstack((leftLine.current_fit, new))\n",
    "                    leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "                elif len(leftLine.current_fit) == 1:\n",
    "                    if leftLine.segment == None:\n",
    "                        new = [rightLine.best_fit[0], rightLine.best_fit[1], leftLine.current_fit[-1][2]]\n",
    "                    else:\n",
    "                        new = [rightLine.best_fit[0], rightLine.best_fit[1], leftLine.segment]\n",
    "                    leftLine.current_fit = [new]\n",
    "                    leftLine.best_fit = new\n",
    "                print('check2 used')\n",
    "        else:\n",
    "            if (rightLine.best_fit[2] > RL and rightLine.best_fit[2] < RR) != 1: # Only right segment out of range\n",
    "                if len(rightLine.current_fit) > 1:\n",
    "                    rightLine.current_fit = np.delete(rightLine.current_fit, -1, 0)\n",
    "                    new = [leftLine.best_fit[0], leftLine.best_fit[1], rightLine.segment]\n",
    "                    rightLine.current_fit = np.vstack((rightLine.current_fit, new))\n",
    "                    rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "                elif len(rightLine.current_fit) == 1:\n",
    "                    if rightLine.segment == None:\n",
    "                        new = [leftLine.best_fit[0], leftLine.best_fit[1], rightLine.current_fit[-1][2]]\n",
    "                    else:\n",
    "                        new = [leftLine.best_fit[0], leftLine.best_fit[1], rightLine.segment]\n",
    "                    rightLine.current_fit = [new]\n",
    "                    rightLine.best_fit = new\n",
    "                print('check3 used')\n",
    "    \n",
    "        # Store segment\n",
    "        leftLine.segment = leftLine.best_fit[2]\n",
    "        rightLine.segment = rightLine.best_fit[2]\n",
    "        \n",
    "    # Check if both lines have similar curvature, as lane lines supposed to be near parallel\n",
    "    if polynomialCheck == 1:\n",
    "        # Check if previous number is available\n",
    "        if (leftLine.polyCF != None and rightLine.polyCF != None):\n",
    "            if (np.absolute(leftLine.best_fit[0] - rightLine.best_fit[0]) / min(np.absolute(leftLine.best_fit[0]), np.absolute(rightLine.best_fit[0])) > 3):\n",
    "                # If left is out of range\n",
    "                if (np.absolute(leftLine.polyCF-leftLine.best_fit[0]) > np.absolute(rightLine.polyCF-rightLine.best_fit[0])):\n",
    "                    leftLine.current_fit[-1][0] = rightLine.best_fit[0]\n",
    "                    leftLine.current_fit[-1][1] = rightLine.best_fit[1]\n",
    "                    if (len(leftLine.current_fit) == 1):\n",
    "                        leftLine.best_fit = leftLine.current_fit[-1]\n",
    "                    else:\n",
    "                        leftLine.best_fit = np.mean(leftLine.current_fit, axis = 0)\n",
    "                    print('check4 used')\n",
    "                # If right is out of range\n",
    "                else:\n",
    "                    rightLine.current_fit[-1][0] = leftLine.best_fit[0]\n",
    "                    rightLine.current_fit[-1][1] = leftLine.best_fit[1]\n",
    "                    if (len(rightLine.current_fit) == 1):\n",
    "                        rightLine.best_fit = rightLine.current_fit[-1]\n",
    "                    else:\n",
    "                        rightLine.best_fit = np.mean(rightLine.current_fit, axis = 0)\n",
    "                    print('check5 used')\n",
    "        \n",
    "        leftLine.polyCF = leftLine.best_fit[0]\n",
    "        rightLine.polyCF = rightLine.best_fit[0]\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    leftLine.current_fitx = leftLine.best_fit[0]*leftLine.ploty**2 + leftLine.best_fit[1]*leftLine.ploty + leftLine.best_fit[2]\n",
    "    rightLine.current_fitx = rightLine.best_fit[0]*rightLine.ploty**2 + rightLine.best_fit[1]*rightLine.ploty + rightLine.best_fit[2]\n",
    "    \n",
    "    if debugMode == 1:\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        window_img = np.zeros_like(out_img)\n",
    "    \n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([leftLine.current_fitx-margin, leftLine.ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([leftLine.current_fitx+margin, leftLine.ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([rightLine.current_fitx-margin, rightLine.ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([rightLine.current_fitx+margin, rightLine.ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "    \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.imshow(result)\n",
    "    \n",
    "    #return leftLine, rightLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slidingWindows() missing 1 required positional argument: 'rightLine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-429-a52f91c16fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrightLine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mslidingWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mknownLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: slidingWindows() missing 1 required positional argument: 'rightLine'"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "#Visualize the result from window search\n",
    "leftLine = Line()\n",
    "rightLine = Line()\n",
    "plt.clf()\n",
    "slidingWindows(warped, leftLine, rightLine, debugMode = 1)\n",
    "knownLines(warped, leftLine, rightLine, debugMode = 1)\n",
    "\n",
    "#plt.imshow(result)\n",
    "#plt.plot(left_fitx, ploty, lw = 10.0, color='red')\n",
    "#plt.plot(right_fitx, ploty, lw = 10.0, color='blue')\n",
    "#plt.xlim(0, 1280)\n",
    "#plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## S5.  Setup helper functions for curvature calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curvatureCalc(leftLine, rightLine):\n",
    "    # Local variables\n",
    "    leftx = leftLine.allx#[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightLine.allx#[::-1]  # Reverse to match top-to-bottom in y\n",
    "    \n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    left_fit = np.polyfit(leftLine.ally*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit = np.polyfit(rightLine.ally*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    leftLine.offcenter = ((leftLine.current_fitx[0] + rightLine.current_fitx[0])/2 - 580) * xm_per_pix #[-1]\n",
    "    rightLine.offcenter = leftLine.offcenter\n",
    "    y_eval = np.max(leftLine.ploty)\n",
    "    leftLine.CR = ((1 + (2*left_fit[0]*y_eval*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    rightLine.CR = ((1 + (2*right_fit[0]*y_eval*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    #return leftLine, rightLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720)\n",
      "478.819933134 m 369.939561719 m\n",
      "off 0.0980303693414 m\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "# Show the calculation result\n",
    "leftLine, rightLine = curvatureCalc(leftLine, rightLine)\n",
    "print(img_size)\n",
    "print(leftLine.CR, 'm', rightLine.CR, 'm')\n",
    "print('off', leftLine.offcenter, 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warpBackLines(left_binary_warped, leftLine, rightLine, Minv):\n",
    "    warp_zero = np.zeros_like(left_binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([leftLine.current_fitx, leftLine.ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rightLine.current_fitx, rightLine.ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    color_warp = cv2.flip(color_warp, 0)\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, img_size) \n",
    "    return newwarp    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1-7. Create the complete filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.current_fitx = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        #store segment value of best fit parameter from previous iteration\n",
    "        self.segment = None\n",
    "        #store polynomial coefficient of best fit parameter from previous iteration\n",
    "        self.polyCF = None\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []\n",
    "        #confidence of last fitted polynomial\n",
    "        self.confidence = None\n",
    "        #erro counter when confidence is low\n",
    "        self.lowConfidenceFlag = 0\n",
    "        #if no good line is found\n",
    "        self.noLineFound = False\n",
    "        #radius of curvature of the line in some units\n",
    "        self.CR = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.offcenter = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = [0,0,0]\n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        #just y-axis for plotting (linspace)\n",
    "        self.ploty = None\n",
    "        #count how many times in a row new line did not match\n",
    "        self.errCount = 0\n",
    "        \n",
    "    def runningWindow(self, newVal, windowSize = 5):\n",
    "        if (len(self.current_fit) == 0):\n",
    "            self.current_fit = [np.asarray(newVal)]\n",
    "            self.best_fit = np.asarray(newVal)\n",
    "        else:\n",
    "            self.diffs[0] = np.absolute(newVal[0] - self.best_fit[0])/np.absolute(self.best_fit[0]) # Percentile\n",
    "            self.diffs[1] = np.absolute(newVal[1] - self.best_fit[1])/np.absolute(self.best_fit[1]) # Percentile\n",
    "            self.diffs[2] = np.absolute(newVal[2] - self.best_fit[2]) # Fixed value\n",
    "            if ((len(self.current_fit) <= 2) or (self.diffs[0] < 0.3 and self.diffs[1] < 0.3 and self.diffs[2] < 50)):\n",
    "                if len(self.current_fit) > windowSize:\n",
    "                    self.current_fit = np.delete(self.current_fit, 0, 0)\n",
    "                self.current_fit = np.vstack((self.current_fit, newVal))\n",
    "                self.best_fit = np.mean(self.current_fit, axis = 0)\n",
    "                if self.errCount <= 0:\n",
    "                    self.errCount = 0\n",
    "                else:\n",
    "                    self.errCount -= 1\n",
    "                    \n",
    "            else:\n",
    "                self.errCount += 1\n",
    "                if self.errCount >= 4:\n",
    "                    self.detected = False\n",
    "                    self.errCount = 0\n",
    "        \n",
    "    # To handle the case when there is no new line found\n",
    "    def addAllX(self, new):\n",
    "        if len(new) != 0:\n",
    "            self.allx = new\n",
    "                \n",
    "    def addAllY(self,new):\n",
    "        if len(new) != 0:\n",
    "            self.ally = new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def advLaneFind(img):\n",
    "\n",
    "    # A1. Apply a distortion correction to raw images\n",
    "    undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    # A1.1 Apply image mask\n",
    "    #leftVertics = np.array([[(200,470),(500, 470),(700,500),(600,600),(330, 650),(330,720),(230,720),(230,650),(120,600),(120,500)]],dtype=np.int32)\n",
    "    leftVertics = np.array([[(150,720),(400,430),(700,430),(700,720)]])\n",
    "    #rightVertics = np.array([[(900,470),(1080, 470),(1280,500),(1280,600),(1170,650),(1170,720),(1070,720),(1070,650),(800,600),(700,500)]],dtype=np.int32)\n",
    "    rightVertics = np.array([[(1250,720),(1000,430),(700,430),(700,720)]],dtype=np.int32)\n",
    "    \n",
    "    leftCropped = regionOfInterest(undistorted,leftVertics)\n",
    "    rightCropped = regionOfInterest(undistorted,rightVertics)\n",
    "    \n",
    "    # A2. Use color transforms, gradients, etc., to create a thresholded binary image\n",
    "    leftCombined = colorTransform(leftCropped)\n",
    "    rightCombined = colorTransform(rightCropped)\n",
    "    \n",
    "    # A3. Apply a perspective transform to rectify binary image (\"birds-eye view\")\n",
    "    left_binary_warped = cv2.warpPerspective(leftCombined, M, img_size, flags=cv2.INTER_NEAREST)\n",
    "    right_binary_warped = cv2.warpPerspective(rightCombined, M, img_size, flags=cv2.INTER_NEAREST)\n",
    "    \n",
    "    left_binary_warped = cv2.flip(left_binary_warped, 0)\n",
    "    right_binary_warped = cv2.flip(right_binary_warped, 0)\n",
    "    \n",
    "    # A4. Detect lane pixels and fit to find the lane boundary\n",
    "    if (leftLine.detected == False or rightLine.detected == False):\n",
    "        print('newLine')\n",
    "        slidingWindows(left_binary_warped, right_binary_warped, leftLine, rightLine, confidenceCheck = 1, polynomialCheck = 0, segmentCheck = 1)\n",
    "    elif (leftLine.detected == True and rightLine.detected == True):\n",
    "        knownLines(left_binary_warped, right_binary_warped, leftLine, rightLine, confidenceCheck = 1, polynomialCheck = 0, segmentCheck = 1)\n",
    "    \n",
    "    if not(leftLine.noLineFound == True and rightLine.noLineFound == True):\n",
    "        # A5. Determine the curvature of the lane and vehicle position with respect to center\n",
    "        curvatureCalc(leftLine, rightLine)\n",
    "        CR = np.around((leftLine.CR + rightLine.CR)/2, decimals = 1)\n",
    "        text = 'Radius of Curvature = ' + str(CR) + '[m]'\n",
    "    \n",
    "        if (leftLine.offcenter > 0):\n",
    "            text2 = 'Left from center by ' + str(np.around(leftLine.offcenter, decimals = 1)) + '[m]'\n",
    "        elif (leftLine.offcenter < 0):\n",
    "            text2 = 'Right from center by ' + str(-np.around(leftLine.offcenter, decimals = 1)) + '[m]'\n",
    "    \n",
    "        # A6. Warp the detected lane boundaries back onto the original image\n",
    "        newwarp = warpBackLines(left_binary_warped, leftLine, rightLine, Minv)\n",
    "    \n",
    "        # A7. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position\n",
    "        result = cv2.addWeighted(undistorted, 1, newwarp, 0.4, 0)\n",
    "        result = cv2.putText(result,text, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)\n",
    "        result = cv2.putText(result,text2, (50,100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)\n",
    "        #result = cv2.putText(result, str(leftLine.best_fit), (50,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        #result = cv2.putText(result, str(rightLine.best_fit), (50,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        #result = cv2.putText(result, str(leftLine.confidence), (50,250), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        #result = cv2.putText(result, str(rightLine.confidence), (50,300), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    else:\n",
    "        warning = 'No lane found, please take control'\n",
    "        #result = cv2.putText(undistorted, warning, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0), 2)\n",
    "        #result = cv2.putText(result, str(leftLine.confidence), (50,250), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        #result = cv2.putText(result, str(rightLine.confidence), (50,300), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "[  1.38606664e-04   1.47784127e-01   2.99931054e+02]\n",
      "[  1.69943952e-04   5.31035786e-02   1.11938658e+03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1336c6b38>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "leftLine = Line()\n",
    "rightLine = Line()\n",
    "img = cv2.imread('test_images/test6.jpg')\n",
    "result = advLaneFind(img)\n",
    "result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "print(leftLine.best_fit)\n",
    "print(rightLine.best_fit)\n",
    "#print('left: ', leftLine.best_fit)\n",
    "#print('right: ', rightLine.best_fit)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply complete filter to the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "[MoviePy] >>>> Building video outputs/prcsd_project_video.mp4\n",
      "[MoviePy] Writing video outputs/prcsd_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1261 [00:03<10:27,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 8/1261 [00:04<10:24,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1261 [00:07<10:12,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 15/1261 [00:07<10:09,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1261 [00:10<10:22,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 26/1261 [00:13<10:12,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1261 [00:16<10:38,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 46/1261 [00:22<09:46,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 53/1261 [00:26<10:07,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 60/1261 [00:29<10:12,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 69/1261 [00:34<09:44,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 76/1261 [00:37<09:55,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 83/1261 [00:41<09:19,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 90/1261 [00:44<09:13,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 97/1261 [00:47<09:15,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 103/1261 [00:50<09:07,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 111/1261 [00:54<09:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 117/1261 [00:57<08:59,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 124/1261 [01:00<09:08,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 131/1261 [01:03<08:59,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 138/1261 [01:07<09:08,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 145/1261 [01:10<09:09,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 154/1261 [01:15<09:03,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 160/1261 [01:18<08:49,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 174/1261 [01:25<09:11,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 181/1261 [01:28<08:50,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 188/1261 [01:32<09:16,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 198/1261 [01:37<09:03,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 207/1261 [01:41<08:42,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 217/1261 [01:46<09:09,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 225/1261 [01:50<08:29,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 232/1261 [01:54<08:58,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 239/1261 [01:57<08:35,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 247/1261 [02:01<08:23,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 255/1261 [02:05<08:11,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 264/1261 [02:10<08:14,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 271/1261 [02:13<08:21,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 280/1261 [02:18<08:21,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 289/1261 [02:22<07:42,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 296/1261 [02:25<07:37,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 303/1261 [02:29<07:33,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 309/1261 [02:32<07:45,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 315/1261 [02:35<08:06,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 321/1261 [02:38<07:59,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 327/1261 [02:41<07:52,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 333/1261 [02:44<07:48,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 339/1261 [02:47<07:21,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 346/1261 [02:50<07:45,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 353/1261 [02:54<07:47,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 360/1261 [02:58<07:49,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 367/1261 [03:01<07:40,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 374/1261 [03:05<07:44,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 381/1261 [03:08<07:09,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 388/1261 [03:12<07:15,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 395/1261 [03:15<07:30,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 402/1261 [03:19<07:43,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 410/1261 [03:23<07:06,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 416/1261 [03:26<06:47,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 422/1261 [03:29<06:38,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 429/1261 [03:32<07:10,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 435/1261 [03:36<07:04,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 442/1261 [03:39<06:32,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 449/1261 [03:42<06:32,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 456/1261 [03:46<06:21,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 463/1261 [03:49<06:23,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 470/1261 [03:52<06:21,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 477/1261 [03:56<06:52,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 484/1261 [04:00<06:58,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 491/1261 [04:03<06:36,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 498/1261 [04:07<06:14,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 505/1261 [04:10<06:15,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 512/1261 [04:14<06:10,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 519/1261 [04:17<06:01,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 526/1261 [04:21<06:16,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 532/1261 [04:24<06:23,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 538/1261 [04:27<05:53,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 545/1261 [04:30<05:41,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 552/1261 [04:34<05:39,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 558/1261 [04:36<05:42,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 564/1261 [04:40<05:59,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 570/1261 [04:42<05:33,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 577/1261 [04:46<05:24,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 583/1261 [04:49<05:45,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 589/1261 [04:52<05:19,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 595/1261 [04:55<05:31,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 601/1261 [04:58<05:31,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 607/1261 [05:01<05:22,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 614/1261 [05:04<05:19,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 620/1261 [05:07<05:26,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 626/1261 [05:10<05:23,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 633/1261 [05:14<05:13,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 639/1261 [05:17<05:49,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 646/1261 [05:20<05:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 660/1261 [05:27<04:51,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 671/1261 [05:33<04:42,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 682/1261 [05:38<04:39,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 688/1261 [05:41<04:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 696/1261 [05:45<04:32,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 703/1261 [05:48<04:48,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 715/1261 [05:54<04:18,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 722/1261 [05:58<04:15,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 730/1261 [06:01<04:18,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 737/1261 [06:05<04:09,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 744/1261 [06:08<04:10,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 751/1261 [06:12<04:06,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 760/1261 [06:16<03:59,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 772/1261 [06:22<04:08,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 774/1261 [06:23<04:05,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 777/1261 [06:24<04:06,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 780/1261 [06:26<04:06,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 781/1261 [06:26<04:06,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 782/1261 [06:27<04:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 786/1261 [06:29<03:48,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 787/1261 [06:29<03:47,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 788/1261 [06:30<03:48,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 793/1261 [06:32<03:45,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 794/1261 [06:33<03:48,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 795/1261 [06:33<03:51,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 800/1261 [06:36<03:46,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 801/1261 [06:36<03:50,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 802/1261 [06:37<03:55,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 807/1261 [06:39<03:46,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 811/1261 [06:41<03:37,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 814/1261 [06:43<03:35,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 815/1261 [06:43<03:34,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 816/1261 [06:44<03:32,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 821/1261 [06:46<03:42,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 828/1261 [06:50<03:34,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 835/1261 [06:53<03:34,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 842/1261 [06:56<03:22,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 854/1261 [07:02<03:16,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 862/1261 [07:06<03:13,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 868/1261 [07:09<03:11,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 875/1261 [07:13<03:17,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 887/1261 [07:19<03:09,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 896/1261 [07:23<03:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 902/1261 [07:26<02:54,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 909/1261 [07:29<02:57,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 916/1261 [07:33<02:46,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 923/1261 [07:36<02:53,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 931/1261 [07:40<02:52,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 944/1261 [07:47<02:45,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 950/1261 [07:50<02:33,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 956/1261 [07:53<02:27,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 963/1261 [07:56<02:23,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 970/1261 [08:00<02:20,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 979/1261 [08:04<02:15,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 985/1261 [08:07<02:11,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 992/1261 [08:10<02:07,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 999/1261 [08:14<02:04,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1006/1261 [08:17<02:01,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1013/1261 [08:20<01:58,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1020/1261 [08:24<01:55,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 1027/1261 [08:27<01:49,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1034/1261 [08:30<01:46,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1040/1261 [08:33<01:43,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1046/1261 [08:36<01:41,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1052/1261 [08:39<01:43,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1058/1261 [08:42<01:36,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1065/1261 [08:45<01:33,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1076/1261 [08:50<01:27,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1083/1261 [08:54<01:23,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1090/1261 [08:57<01:22,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1101/1261 [09:02<01:18,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1109/1261 [09:06<01:13,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1115/1261 [09:09<01:10,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1121/1261 [09:12<01:07,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1128/1261 [09:15<01:03,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1135/1261 [09:19<01:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1142/1261 [09:22<00:57,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1150/1261 [09:26<00:53,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1157/1261 [09:29<00:50,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1166/1261 [09:34<00:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1173/1261 [09:37<00:42,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1180/1261 [09:40<00:38,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1187/1261 [09:44<00:38,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1193/1261 [09:47<00:33,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1200/1261 [09:50<00:29,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1207/1261 [09:54<00:25,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 1208/1261 [09:54<00:25,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1216/1261 [09:58<00:21,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1230/1261 [10:05<00:15,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 1231/1261 [10:05<00:14,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 1232/1261 [10:06<00:14,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1237/1261 [10:08<00:12,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 1238/1261 [10:09<00:11,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1244/1261 [10:12<00:08,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 1245/1261 [10:12<00:07,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 1246/1261 [10:13<00:07,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1248/1261 [10:14<00:06,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 1249/1261 [10:14<00:05,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1251/1261 [10:15<00:04,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 1252/1261 [10:16<00:04,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 1253/1261 [10:16<00:03,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1255/1261 [10:17<00:02,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [10:20<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "check3 used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: outputs/prcsd_project_video.mp4 \n",
      "\n",
      "CPU times: user 11min 15s, sys: 2min 15s, total: 13min 30s\n",
      "Wall time: 10min 21s\n"
     ]
    }
   ],
   "source": [
    "leftLine = Line()\n",
    "rightLine = Line()\n",
    "white_output = 'outputs/prcsd_project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(advLaneFind)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"outputs/prcsd_project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Play the video on notebook\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "[MoviePy] >>>> Building video outputs/prcsd_challenge_video.mp4\n",
      "[MoviePy] Writing video outputs/prcsd_challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/485 [00:03<04:04,  1.96it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-173>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-172>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-171>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    347\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                            \u001b[0mffmpeg_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mffmpeg_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                            progress_bar=progress_bar)\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     for t,frame in clip.iter_frames(progress_bar=progress_bar, with_times=True,\n\u001b[0;32m--> 209\u001b[0;31m                                     fps=fps, dtype=\"uint8\"):\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                 \u001b[0;31m# Update and print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-136>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shiono/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-41fdbfb0b220>\u001b[0m in \u001b[0;36madvLaneFind\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# A2. Use color transforms, gradients, etc., to create a thresholded binary image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mleftCombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftCropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mrightCombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrightCropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-3b769fc261b0>\u001b[0m in \u001b[0;36mcolorTransform\u001b[0;34m(undistorted)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcolorTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundistorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgradx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_sobel_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundistorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mHLSS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundistorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamicMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# originally: (150,255)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mHLSH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundistorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamicMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mBGRR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundistorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-80b1a0b7b7df>\u001b[0m in \u001b[0;36mabs_sobel_thresh\u001b[0;34m(img, orient, sobel_kernel, thresh)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mabsSobel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSobel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msobel_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 3. Scale to 8-bit and convert to uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mscaledSobel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mabsSobel\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsSobel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 4. Create a mask of 1s based on threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgrad_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaledSobel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "leftLine = Line()\n",
    "rightLine = Line()\n",
    "white_output = 'outputs/prcsd_challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(advLaneFind)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"outputs/prcsd_challenge_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Play the video on notebook\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n",
      "[MoviePy] >>>> Building video outputs/prcsd_harder_challenge_video.mp4\n",
      "[MoviePy] Writing video outputs/prcsd_harder_challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/1200 [00:00<10:35,  1.89it/s]\u001b[A\n",
      "  0%|          | 2/1200 [00:01<10:44,  1.86it/s]\u001b[A\n",
      "  0%|          | 3/1200 [00:01<10:41,  1.87it/s]\u001b[A\n",
      "  0%|          | 4/1200 [00:02<10:43,  1.86it/s]\u001b[A\n",
      "  0%|          | 5/1200 [00:02<10:51,  1.83it/s]\u001b[A\n",
      "  0%|          | 6/1200 [00:03<10:47,  1.85it/s]\u001b[A\n",
      "  1%|          | 7/1200 [00:03<10:45,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  1%|          | 8/1200 [00:04<10:37,  1.87it/s]\u001b[A\n",
      "  1%|          | 9/1200 [00:04<10:43,  1.85it/s]\u001b[A\n",
      "  1%|          | 10/1200 [00:05<10:45,  1.84it/s]\u001b[A\n",
      "  1%|          | 11/1200 [00:05<10:36,  1.87it/s]\u001b[A\n",
      "  1%|          | 12/1200 [00:06<10:30,  1.88it/s]\u001b[A\n",
      "  1%|          | 13/1200 [00:06<10:34,  1.87it/s]\u001b[A\n",
      "  1%|          | 14/1200 [00:07<10:25,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  1%|▏         | 15/1200 [00:08<10:17,  1.92it/s]\u001b[A\n",
      "  1%|▏         | 16/1200 [00:08<10:20,  1.91it/s]\u001b[A\n",
      "  1%|▏         | 17/1200 [00:09<10:21,  1.90it/s]\u001b[A\n",
      "  2%|▏         | 18/1200 [00:09<10:15,  1.92it/s]\u001b[A\n",
      "  2%|▏         | 19/1200 [00:10<10:16,  1.92it/s]\u001b[A\n",
      "  2%|▏         | 20/1200 [00:10<10:15,  1.92it/s]\u001b[A\n",
      "  2%|▏         | 21/1200 [00:11<10:11,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  2%|▏         | 22/1200 [00:11<10:10,  1.93it/s]\u001b[A\n",
      "  2%|▏         | 23/1200 [00:12<10:04,  1.95it/s]\u001b[A\n",
      "  2%|▏         | 24/1200 [00:12<10:01,  1.95it/s]\u001b[A\n",
      "  2%|▏         | 25/1200 [00:13<10:02,  1.95it/s]\u001b[A\n",
      "  2%|▏         | 26/1200 [00:13<10:07,  1.93it/s]\u001b[A\n",
      "  2%|▏         | 27/1200 [00:14<10:02,  1.95it/s]\u001b[A\n",
      "  2%|▏         | 28/1200 [00:14<10:06,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  2%|▏         | 29/1200 [00:15<10:07,  1.93it/s]\u001b[A\n",
      "  2%|▎         | 30/1200 [00:15<10:05,  1.93it/s]\u001b[A\n",
      "  3%|▎         | 31/1200 [00:16<10:10,  1.91it/s]\u001b[A\n",
      "  3%|▎         | 32/1200 [00:16<10:08,  1.92it/s]\u001b[A\n",
      "  3%|▎         | 33/1200 [00:17<10:05,  1.93it/s]\u001b[A\n",
      "  3%|▎         | 34/1200 [00:17<10:02,  1.93it/s]\u001b[A\n",
      "  3%|▎         | 35/1200 [00:18<10:04,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  3%|▎         | 36/1200 [00:18<10:02,  1.93it/s]\u001b[A\n",
      "  3%|▎         | 37/1200 [00:19<09:58,  1.94it/s]\u001b[A\n",
      "  3%|▎         | 38/1200 [00:19<09:54,  1.95it/s]\u001b[A\n",
      "  3%|▎         | 39/1200 [00:20<09:54,  1.95it/s]\u001b[A\n",
      "  3%|▎         | 40/1200 [00:20<09:57,  1.94it/s]\u001b[A\n",
      "  3%|▎         | 41/1200 [00:21<09:56,  1.94it/s]\u001b[A\n",
      "  4%|▎         | 42/1200 [00:21<10:02,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  4%|▎         | 43/1200 [00:22<10:02,  1.92it/s]\u001b[A\n",
      "  4%|▎         | 44/1200 [00:23<10:02,  1.92it/s]\u001b[A\n",
      "  4%|▍         | 45/1200 [00:23<09:55,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 46/1200 [00:24<09:55,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 47/1200 [00:24<09:53,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 48/1200 [00:25<09:55,  1.93it/s]\u001b[A\n",
      "  4%|▍         | 49/1200 [00:25<09:53,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  4%|▍         | 50/1200 [00:26<09:58,  1.92it/s]\u001b[A\n",
      "  4%|▍         | 51/1200 [00:26<09:52,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 52/1200 [00:27<09:53,  1.93it/s]\u001b[A\n",
      "  4%|▍         | 53/1200 [00:27<09:49,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 54/1200 [00:28<09:54,  1.93it/s]\u001b[A\n",
      "  5%|▍         | 55/1200 [00:28<09:49,  1.94it/s]\u001b[A\n",
      "  5%|▍         | 56/1200 [00:29<09:49,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  5%|▍         | 57/1200 [00:29<09:45,  1.95it/s]\u001b[A\n",
      "  5%|▍         | 58/1200 [00:30<09:47,  1.95it/s]\u001b[A\n",
      "  5%|▍         | 59/1200 [00:30<09:44,  1.95it/s]\u001b[A\n",
      "  5%|▌         | 60/1200 [00:31<09:45,  1.95it/s]\u001b[A\n",
      "  5%|▌         | 61/1200 [00:31<09:45,  1.95it/s]\u001b[A\n",
      "  5%|▌         | 62/1200 [00:32<09:42,  1.95it/s]\u001b[A\n",
      "  5%|▌         | 63/1200 [00:32<09:39,  1.96it/s]\u001b[A\n",
      "  5%|▌         | 64/1200 [00:33<09:40,  1.96it/s]\u001b[A\n",
      "  5%|▌         | 65/1200 [00:33<09:42,  1.95it/s]\u001b[A\n",
      "  6%|▌         | 66/1200 [00:34<09:41,  1.95it/s]\u001b[A\n",
      "  6%|▌         | 67/1200 [00:34<09:40,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  6%|▌         | 68/1200 [00:35<09:39,  1.95it/s]\u001b[A\n",
      "  6%|▌         | 69/1200 [00:35<09:39,  1.95it/s]\u001b[A\n",
      "  6%|▌         | 70/1200 [00:36<09:40,  1.95it/s]\u001b[A\n",
      "  6%|▌         | 71/1200 [00:36<09:39,  1.95it/s]\u001b[A\n",
      "  6%|▌         | 72/1200 [00:37<09:36,  1.96it/s]\u001b[A\n",
      "  6%|▌         | 73/1200 [00:37<09:34,  1.96it/s]\u001b[A\n",
      "  6%|▌         | 74/1200 [00:38<09:35,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  6%|▋         | 75/1200 [00:38<09:36,  1.95it/s]\u001b[A\n",
      "  6%|▋         | 76/1200 [00:39<09:30,  1.97it/s]\u001b[A\n",
      "  6%|▋         | 77/1200 [00:39<09:28,  1.97it/s]\u001b[A\n",
      "  6%|▋         | 78/1200 [00:40<09:33,  1.96it/s]\u001b[A\n",
      "  7%|▋         | 79/1200 [00:40<09:34,  1.95it/s]\u001b[A\n",
      "  7%|▋         | 80/1200 [00:41<09:32,  1.96it/s]\u001b[A\n",
      "  7%|▋         | 81/1200 [00:42<09:33,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  7%|▋         | 82/1200 [00:42<09:30,  1.96it/s]\u001b[A\n",
      "  7%|▋         | 83/1200 [00:43<09:30,  1.96it/s]\u001b[A\n",
      "  7%|▋         | 84/1200 [00:43<09:31,  1.95it/s]\u001b[A\n",
      "  7%|▋         | 85/1200 [00:44<09:27,  1.96it/s]\u001b[A\n",
      "  7%|▋         | 86/1200 [00:44<09:25,  1.97it/s]\u001b[A\n",
      "  7%|▋         | 87/1200 [00:45<09:23,  1.98it/s]\u001b[A\n",
      "  7%|▋         | 88/1200 [00:45<09:21,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  7%|▋         | 89/1200 [00:46<09:20,  1.98it/s]\u001b[A\n",
      "  8%|▊         | 90/1200 [00:46<09:23,  1.97it/s]\u001b[A\n",
      "  8%|▊         | 91/1200 [00:47<09:22,  1.97it/s]\u001b[A\n",
      "  8%|▊         | 92/1200 [00:47<09:25,  1.96it/s]\u001b[A\n",
      "  8%|▊         | 93/1200 [00:48<09:27,  1.95it/s]\u001b[A\n",
      "  8%|▊         | 94/1200 [00:48<09:26,  1.95it/s]\u001b[A\n",
      "  8%|▊         | 95/1200 [00:49<09:29,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  8%|▊         | 96/1200 [00:49<09:31,  1.93it/s]\u001b[A\n",
      "  8%|▊         | 97/1200 [00:50<09:34,  1.92it/s]\u001b[A\n",
      "  8%|▊         | 98/1200 [00:50<09:34,  1.92it/s]\u001b[A\n",
      "  8%|▊         | 99/1200 [00:51<09:30,  1.93it/s]\u001b[A\n",
      "  8%|▊         | 100/1200 [00:51<09:26,  1.94it/s]\u001b[A\n",
      "  8%|▊         | 101/1200 [00:52<09:15,  1.98it/s]\u001b[A\n",
      "  8%|▊         | 102/1200 [00:52<09:14,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  9%|▊         | 103/1200 [00:53<09:21,  1.95it/s]\u001b[A\n",
      "  9%|▊         | 104/1200 [00:53<09:31,  1.92it/s]"
     ]
    }
   ],
   "source": [
    "leftLine = Line()\n",
    "rightLine = Line()\n",
    "white_output = 'outputs/prcsd_harder_challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(advLaneFind)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the video on notebook\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
